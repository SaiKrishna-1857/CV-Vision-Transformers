{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f543d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adapted from https://github.com/lukemelas/simple-bert\n",
    "\"\"\"\n",
    " \n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import Tensor \n",
    "from torch.nn import functional as F\n",
    "\n",
    "PEFT = 0\n",
    "\n",
    "def split_last(x, shape):\n",
    "    \"split the last dimension to given shape\"\n",
    "    shape = list(shape)\n",
    "    assert shape.count(-1) <= 1\n",
    "    if -1 in shape:\n",
    "        shape[shape.index(-1)] = int(x.size(-1) / -np.prod(shape))\n",
    "    return x.view(*x.size()[:-1], *shape)\n",
    "\n",
    "\n",
    "def merge_last(x, n_dims):\n",
    "    \"merge the last n_dims to a dimension\"\n",
    "    s = x.size()\n",
    "    assert n_dims > 1 and n_dims < len(s)\n",
    "    return x.view(*s[:-n_dims], -1)\n",
    "\n",
    "class TrainableEltwiseLayer(nn.Module):\n",
    "    def __init__(self, n, h, w):\n",
    "        super(TrainableEltwiseLayer, self).__init__()\n",
    "        self.weights = nn.Parameter(torch.Tensor(1, n, h, w))  # define the trainable parameter\n",
    "\n",
    "    def forward(self, x):\n",
    "        # assuming x is of size b-1-h-w\n",
    "        return x * self.weights  # element-wise multiplication\n",
    "\n",
    "\n",
    "class MultiHeadedSelfAttention(nn.Module):\n",
    "    \"\"\"Multi-Headed Dot Product Attention\"\"\"\n",
    "    def __init__(self, dim, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.proj_q = nn.Linear(dim, dim)\n",
    "        self.proj_k = nn.Linear(dim, dim)\n",
    "        self.proj_v = nn.Linear(dim, dim)\n",
    "        \n",
    "        head_dim = dim // num_heads\n",
    "\n",
    "#         self.lk = TrainableEltwiseLayer(1, head_dim, 1)\n",
    "#         nn.init.ones_(self.lk.weights)\n",
    "#         self.lv = TrainableEltwiseLayer(1, 1, head_dim)\n",
    "#         nn.init.ones_(self.lv.weights)\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.n_heads = num_heads\n",
    "        self.scores = None # for visualization\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        x, q(query), k(key), v(value) : (B(batch_size), S(seq_len), D(dim))\n",
    "        mask : (B(batch_size) x S(seq_len))\n",
    "        * split D(dim) into (H(n_heads), W(width of head)) ; D = H * W\n",
    "        \"\"\"\n",
    "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        q, k, v = self.proj_q(x), self.proj_k(x), self.proj_v(x)\n",
    "        q, k, v = (split_last(x, (self.n_heads, -1)).transpose(1, 2) for x in [q, k, v])\n",
    "        \n",
    "        #PEFT\n",
    "        #if PEFT:\n",
    "#         k = self.lk(k.transpose(-2, -1))\n",
    "#         v = self.lv(v)\n",
    "#         scores = q @ k / np.sqrt(k.size(-1))\n",
    "#         else:\n",
    "#           # (B, H, S, W) @ (B, H, W, S) -> (B, H, S, S) -softmax-> (B, H, S, S)\n",
    "        scores = q @ k.transpose(-2, -1) / np.sqrt(k.size(-1))\n",
    "        if mask is not None:\n",
    "            mask = mask[:, None, None, :].float()\n",
    "            scores -= 10000.0 * (1.0 - mask)\n",
    "        scores = self.drop(F.softmax(scores, dim=-1))\n",
    "        # (B, H, S, S) @ (B, H, S, W) -> (B, H, S, W) -trans-> (B, S, H, W)\n",
    "        h = (scores @ v).transpose(1, 2).contiguous()\n",
    "        # -merge-> (B, S, D)\n",
    "        h = merge_last(h, 2)\n",
    "        self.scores = scores\n",
    "        return h\n",
    "\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    \"\"\"FeedForward Neural Networks for each position\"\"\"\n",
    "    def __init__(self, dim, ff_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, ff_dim)\n",
    "        #PEFT\n",
    "        #if PEFT:\n",
    "#         self.fcpeft = TrainableEltwiseLayer(1, 1, 3072)\n",
    "#         nn.init.ones_(self.fcpeft.weights)\n",
    "        \n",
    "        self.fc2 = nn.Linear(ff_dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (B, S, D) -> (B, S, D_ff) -> (B, S, D)\n",
    "        # if PEFT:\n",
    "        #     return self.fc2(self.fcpeft(F.gelu(self.fc1(x))))\n",
    "        x = F.gelu(self.fc1(x))\n",
    "        #if PEFT:\n",
    "#         x = self.fcpeft(x)\n",
    "#         x = x.squeeze(0)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"Transformer Block\"\"\"\n",
    "    def __init__(self, dim, num_heads, ff_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadedSelfAttention(dim, num_heads, dropout)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.norm1 = nn.LayerNorm(dim, eps=1e-6)\n",
    "        self.pwff = PositionWiseFeedForward(dim, ff_dim)\n",
    "        self.norm2 = nn.LayerNorm(dim, eps=1e-6)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        h = self.drop(self.proj(self.attn(self.norm1(x), mask)))\n",
    "        x = x + h\n",
    "        h = self.drop(self.pwff(self.norm2(x)))\n",
    "        x = x + h\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"Transformer with Self-Attentive Blocks\"\"\"\n",
    "    def __init__(self, num_layers, dim, num_heads, ff_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(dim, num_heads, ff_dim, dropout) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        for block in self.blocks:\n",
    "            x = block(x, mask)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6028dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model.py - Model and module class for ViT.\n",
    "   They are built to mirror those in the official Jax implementation.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Optional\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from pytorch_pretrained_vit.utils import load_pretrained_weights, as_tuple\n",
    "from pytorch_pretrained_vit.configs import PRETRAINED_MODELS\n",
    "\n",
    "\n",
    "class PositionalEmbedding1D(nn.Module):\n",
    "    \"\"\"Adds (optionally learned) positional embeddings to the inputs.\"\"\"\n",
    "\n",
    "    def __init__(self, seq_len, dim):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = nn.Parameter(torch.zeros(1, seq_len, dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Input has shape `(batch_size, seq_len, emb_dim)`\"\"\"\n",
    "        return x + self.pos_embedding\n",
    "\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        name (str): Model name, e.g. 'B_16'\n",
    "        pretrained (bool): Load pretrained weights\n",
    "        in_channels (int): Number of channels in input data\n",
    "        num_classes (int): Number of classes, default 1000\n",
    "\n",
    "    References:\n",
    "        [1] https://openreview.net/forum?id=YicbFdNTTy\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        name: Optional[str] = None, \n",
    "        pretrained: bool = False, \n",
    "        patches: int = 16,\n",
    "        dim: int = 768,\n",
    "        ff_dim: int = 3072,\n",
    "        num_heads: int = 12,\n",
    "        num_layers: int = 12,\n",
    "        attention_dropout_rate: float = 0.0,\n",
    "        dropout_rate: float = 0.1,\n",
    "        representation_size: Optional[int] = None,\n",
    "        load_repr_layer: bool = False,\n",
    "        classifier: str = 'token',\n",
    "        positional_embedding: str = '1d',\n",
    "        in_channels: int = 3, \n",
    "        image_size: Optional[int] = None,\n",
    "        num_classes: Optional[int] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Configuration\n",
    "        if name is None:\n",
    "            check_msg = 'must specify name of pretrained model'\n",
    "            assert not pretrained, check_msg\n",
    "            #assert not resize_positional_embedding, check_msg\n",
    "            if num_classes is None:\n",
    "                num_classes = 1000\n",
    "            if image_size is None:\n",
    "                image_size = 384\n",
    "        else:  # load pretrained model\n",
    "            assert name in PRETRAINED_MODELS.keys(), \\\n",
    "                'name should be in: ' + ', '.join(PRETRAINED_MODELS.keys())\n",
    "            config = PRETRAINED_MODELS[name]['config']\n",
    "            patches = config['patches']\n",
    "            dim = config['dim']\n",
    "            ff_dim = config['ff_dim']\n",
    "            num_heads = config['num_heads']\n",
    "            num_layers = config['num_layers']\n",
    "            attention_dropout_rate = config['attention_dropout_rate']\n",
    "            dropout_rate = config['dropout_rate']\n",
    "            representation_size = config['representation_size']\n",
    "            classifier = config['classifier']\n",
    "            if image_size is None:\n",
    "                image_size = PRETRAINED_MODELS[name]['image_size']\n",
    "            if num_classes is None:\n",
    "                num_classes = PRETRAINED_MODELS[name]['num_classes']\n",
    "        self.image_size = image_size                \n",
    "\n",
    "        # Image and patch sizes\n",
    "        h, w = as_tuple(image_size)  # image sizes\n",
    "        fh, fw = as_tuple(patches)  # patch sizes\n",
    "        gh, gw = h // fh, w // fw  # number of patches\n",
    "        seq_len = gh * gw\n",
    "\n",
    "        # Patch embedding\n",
    "        self.patch_embedding = nn.Conv2d(in_channels, dim, kernel_size=(fh, fw), stride=(fh, fw))\n",
    "\n",
    "        # Class token\n",
    "        if classifier == 'token':\n",
    "            self.class_token = nn.Parameter(torch.zeros(1, 1, dim))\n",
    "            seq_len += 1\n",
    "        \n",
    "        # Positional embedding\n",
    "        if positional_embedding.lower() == '1d':\n",
    "            self.positional_embedding = PositionalEmbedding1D(seq_len, dim)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "        # Transformer\n",
    "        self.transformer = Transformer(num_layers=num_layers, dim=dim, num_heads=num_heads, \n",
    "                                       ff_dim=ff_dim, dropout=dropout_rate)\n",
    "        \n",
    "        # Representation layer\n",
    "        if representation_size and load_repr_layer:\n",
    "            self.pre_logits = nn.Linear(dim, representation_size)\n",
    "            pre_logits_size = representation_size\n",
    "        else:\n",
    "            pre_logits_size = dim\n",
    "\n",
    "        # Classifier head\n",
    "        self.norm = nn.LayerNorm(pre_logits_size, eps=1e-6)\n",
    "        self.fc = nn.Linear(pre_logits_size, num_classes)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        # Load pretrained model\n",
    "        if pretrained:\n",
    "            pretrained_num_channels = 3\n",
    "            pretrained_num_classes = PRETRAINED_MODELS[name]['num_classes']\n",
    "            pretrained_image_size = PRETRAINED_MODELS[name]['image_size']\n",
    "            load_pretrained_weights(\n",
    "                self, name, \n",
    "                load_first_conv=(in_channels == pretrained_num_channels),\n",
    "                load_fc=(num_classes == pretrained_num_classes),\n",
    "                load_repr_layer=load_repr_layer,\n",
    "                resize_positional_embedding=(image_size != pretrained_image_size),\n",
    "            )\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def init_weights(self):\n",
    "        def _init(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)  # _trunc_normal(m.weight, std=0.02)  # from .initialization import _trunc_normal\n",
    "                if hasattr(m, 'bias') and m.bias is not None:\n",
    "                    nn.init.normal_(m.bias, std=1e-6)  # nn.init.constant(m.bias, 0)\n",
    "        self.apply(_init)\n",
    "        nn.init.constant_(self.fc.weight, 0)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.normal_(self.positional_embedding.pos_embedding, std=0.02)  # _trunc_normal(self.positional_embedding.pos_embedding, std=0.02)\n",
    "        nn.init.constant_(self.class_token, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Breaks image into patches, applies transformer, applies MLP head.\n",
    "\n",
    "        Args:\n",
    "            x (tensor): `b,c,fh,fw`\n",
    "        \"\"\"\n",
    "        b, c, fh, fw = x.shape\n",
    "        x = self.patch_embedding(x)  # b,d,gh,gw\n",
    "        x = x.flatten(2).transpose(1, 2)  # b,gh*gw,d\n",
    "        if hasattr(self, 'class_token'):\n",
    "            x = torch.cat((self.class_token.expand(b, -1, -1), x), dim=1)  # b,gh*gw+1,d\n",
    "        if hasattr(self, 'positional_embedding'): \n",
    "            x = self.positional_embedding(x)  # b,gh*gw+1,d \n",
    "        x = self.transformer(x)  # b,gh*gw+1,d\n",
    "        if hasattr(self, 'pre_logits'):\n",
    "            x = self.pre_logits(x)\n",
    "            x = torch.tanh(x)\n",
    "        if hasattr(self, 'fc'):\n",
    "            x = self.norm(x)[:, 0]  # b,d\n",
    "            x = self.fc(x)  # b,num_classes\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "497e7738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebbf0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.datasets import CUB\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "batch_size = 128\n",
    "n_workers = 4\n",
    "\n",
    "train_set = CUB(split=\"train\", transform = transforms.Compose([transforms.ToTensor(),transforms.Resize((384, 384))]), training=True)\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d05ce395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(set(train_set.get_labels()))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38d228e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUBModel(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super().__init__()\n",
    "        self.vit = ViT('B_32_imagenet1k',pretrained=False)\n",
    "        self.linear_last = nn.Linear(1000,num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.vit(xb)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear_last(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54d36e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CUBModel(num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "911f8a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.samplers import TaskSampler\n",
    "\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "n_way = 5\n",
    "n_shot = 5\n",
    "n_query = 10\n",
    "\n",
    "test_set = CUB(split=\"test\", transform = transforms.Compose([transforms.ToTensor(),transforms.Resize((384, 384))]), training=False)\n",
    "\n",
    "n_test_tasks = 50\n",
    "test_sampler = TaskSampler(\n",
    "    test_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_test_tasks\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_sampler=test_sampler,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=test_sampler.episodic_collate_fn,\n",
    ")\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "def evaluate_query(model, images, labels):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    out = model(images) \n",
    "    loss = F.cross_entropy(out, labels)\n",
    "    acc = accuracy(out, labels)\n",
    "    return acc\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "473fcb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = []\n",
    "for batch in test_loader:\n",
    "    batch_list.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8543157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 10\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.788136601448059\n",
      "Training Loss is 50.99111344665289\n",
      "Training Loss is 59.22685953229666\n",
      "Training Loss is 65.02861731871963\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.971954345703125\n",
      "Training Loss is 62.69901339709759\n",
      "Training Loss is 72.66159962117672\n",
      "Training Loss is 79.5210037343204\n",
      "0.7599999904632568\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.8240814208984375\n",
      "Training Loss is 57.16128171980381\n",
      "Training Loss is 66.75165562331676\n",
      "Training Loss is 73.4557129740715\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.9187426567077637\n",
      "Training Loss is 54.04993902891874\n",
      "Training Loss is 62.56557551026344\n",
      "Training Loss is 68.4920959174633\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.8762203454971313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is 64.87802556157112\n",
      "Training Loss is 77.67067790776491\n",
      "Training Loss is 86.54957052320242\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 2.2462263107299805\n",
      "Training Loss is 80.4259876459837\n",
      "Training Loss is 95.18658483028412\n",
      "Training Loss is 105.29486271739006\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.7102470397949219\n",
      "Training Loss is 51.699783481657505\n",
      "Training Loss is 60.36398987472057\n",
      "Training Loss is 66.29794643446803\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 2.125060796737671\n",
      "Training Loss is 61.447170585393906\n",
      "Training Loss is 71.61437737196684\n",
      "Training Loss is 78.76090884581208\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.5076985359191895\n",
      "Training Loss is 43.97460927069187\n",
      "Training Loss is 51.19958782568574\n",
      "Training Loss is 56.317193783819675\n",
      "0.8799999952316284\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.802636981010437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is 62.45917774736881\n",
      "Training Loss is 74.90675653517246\n",
      "Training Loss is 83.57948070764542\n",
      "0.8799999952316284\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.8702517747879028\n",
      "Training Loss is 70.462800770998\n",
      "Training Loss is 85.78209417313337\n",
      "Training Loss is 96.41182177513838\n",
      "0.8600000143051147\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.8259283304214478\n",
      "Training Loss is 53.70406091213226\n",
      "Training Loss is 62.35052144899964\n",
      "Training Loss is 68.23067549616098\n",
      "0.9599999785423279\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 2.0896711349487305\n",
      "Training Loss is 61.32654559612274\n",
      "Training Loss is 71.1122284680605\n",
      "Training Loss is 77.87979703769088\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.8871750831604004\n",
      "Training Loss is 51.516380444169044\n",
      "Training Loss is 59.12883264943957\n",
      "Training Loss is 64.51560843363404\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 2.080465316772461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is 69.58752398192883\n",
      "Training Loss is 81.8641387373209\n",
      "Training Loss is 90.33695640414953\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.431450605392456\n",
      "Training Loss is 44.942150577902794\n",
      "Training Loss is 53.568787302821875\n",
      "Training Loss is 59.68463361635804\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.920687198638916\n",
      "Training Loss is 57.06527914106846\n",
      "Training Loss is 67.17389906197786\n",
      "Training Loss is 74.24337589740753\n",
      "0.8799999952316284\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 2.1928277015686035\n",
      "Training Loss is 79.10976415872574\n",
      "Training Loss is 97.6320820003748\n",
      "Training Loss is 110.31150069832802\n",
      "0.8399999737739563\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.7774959802627563\n",
      "Training Loss is 53.3332092911005\n",
      "Training Loss is 63.873732797801495\n",
      "Training Loss is 71.23476533591747\n",
      "0.8600000143051147\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.9563120603561401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is 55.93259063363075\n",
      "Training Loss is 64.98009048774838\n",
      "Training Loss is 71.26551017165184\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.8157283067703247\n",
      "Training Loss is 57.74734862148762\n",
      "Training Loss is 68.17513121664524\n",
      "Training Loss is 75.28849103674293\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.5238308906555176\n",
      "Training Loss is 45.316954270005226\n",
      "Training Loss is 53.583508525043726\n",
      "Training Loss is 59.38938218727708\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.790193796157837\n",
      "Training Loss is 62.44101071357727\n",
      "Training Loss is 75.29375832527876\n",
      "Training Loss is 84.36476974189281\n",
      "0.9599999785423279\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.7223374843597412\n",
      "Training Loss is 59.203111574053764\n",
      "Training Loss is 70.44454967230558\n",
      "Training Loss is 78.2096986323595\n",
      "0.7599999904632568\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.8257757425308228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is 58.16931040585041\n",
      "Training Loss is 69.04219924658537\n",
      "Training Loss is 76.45941636711359\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 2.137317657470703\n",
      "Training Loss is 68.96367831528187\n",
      "Training Loss is 83.27380164712667\n",
      "Training Loss is 93.36850070953369\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 2.0880966186523438\n",
      "Training Loss is 66.59557548165321\n",
      "Training Loss is 77.83488281071186\n",
      "Training Loss is 85.61552035063505\n",
      "1.0\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.6930344104766846\n",
      "Training Loss is 63.18830984830856\n",
      "Training Loss is 76.99537331610918\n",
      "Training Loss is 86.64654210954905\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 2.0719242095947266\n",
      "Training Loss is 66.97370313107967\n",
      "Training Loss is 77.86737914383411\n",
      "Training Loss is 85.26869638636708\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.7941217422485352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is 56.95721662044525\n",
      "Training Loss is 67.5614108517766\n",
      "Training Loss is 74.89263455942273\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.955965518951416\n",
      "Training Loss is 59.04604281485081\n",
      "Training Loss is 68.33715942502022\n",
      "Training Loss is 74.75080947205424\n",
      "0.9599999785423279\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.652847170829773\n",
      "Training Loss is 48.775818318128586\n",
      "Training Loss is 57.07152442261577\n",
      "Training Loss is 62.864460933953524\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.696345329284668\n",
      "Training Loss is 57.012319818139076\n",
      "Training Loss is 67.81149632483721\n",
      "Training Loss is 75.27679792046547\n",
      "0.8799999952316284\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.6176306009292603\n",
      "Training Loss is 47.370672546327114\n",
      "Training Loss is 55.30607634782791\n",
      "Training Loss is 60.823364946991205\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.7851916551589966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is 66.04757411777973\n",
      "Training Loss is 78.92369071394205\n",
      "Training Loss is 87.66179888695478\n",
      "0.7799999713897705\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.8957115411758423\n",
      "Training Loss is 56.920567244291306\n",
      "Training Loss is 66.05472895130515\n",
      "Training Loss is 72.3543369807303\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.9998964071273804\n",
      "Training Loss is 65.96129217743874\n",
      "Training Loss is 78.17848746478558\n",
      "Training Loss is 86.53031958639622\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.597447156906128\n",
      "Training Loss is 47.462957203388214\n",
      "Training Loss is 56.45764062553644\n",
      "Training Loss is 62.85746171697974\n",
      "0.9599999785423279\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 2.561720371246338\n",
      "Training Loss is 82.48330235481262\n",
      "Training Loss is 95.58956917375326\n",
      "Training Loss is 104.32924887537956\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.8195019960403442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is 61.906217232346535\n",
      "Training Loss is 73.25086195766926\n",
      "Training Loss is 81.04978217929602\n",
      "0.7799999713897705\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.7782155275344849\n",
      "Training Loss is 43.64770318567753\n",
      "Training Loss is 49.445850770920515\n",
      "Training Loss is 53.47046346589923\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 2.1126534938812256\n",
      "Training Loss is 81.52088215947151\n",
      "Training Loss is 100.44462606310844\n",
      "Training Loss is 113.74291855096817\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.7287510633468628\n",
      "Training Loss is 54.22982041537762\n",
      "Training Loss is 64.39775844663382\n",
      "Training Loss is 71.41813288256526\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.8040677309036255\n",
      "Training Loss is 59.570098891854286\n",
      "Training Loss is 70.37185227870941\n",
      "Training Loss is 77.89400379359722\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 2.0246198177337646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is 60.036123156547546\n",
      "Training Loss is 69.05720227956772\n",
      "Training Loss is 75.22141048684716\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 2.034086227416992\n",
      "Training Loss is 63.37787218391895\n",
      "Training Loss is 74.37889897823334\n",
      "Training Loss is 81.91039257869124\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.7113134860992432\n",
      "Training Loss is 46.82308427989483\n",
      "Training Loss is 53.67392639070749\n",
      "Training Loss is 58.480254329741\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.9212760925292969\n",
      "Training Loss is 69.09555996954441\n",
      "Training Loss is 85.6798773035407\n",
      "Training Loss is 97.34530410915613\n",
      "0.8600000143051147\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.538893222808838\n",
      "Training Loss is 49.572107039391994\n",
      "Training Loss is 57.79780239984393\n",
      "Training Loss is 63.50986044108868\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n",
      "Training Loss is 1.6336020231246948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is 55.07974925637245\n",
      "Training Loss is 65.29332509636879\n",
      "Training Loss is 72.32929148897529\n",
      "0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "#model.to(device)\n",
    "\n",
    "print(\"Number of GPUs: \"+str(n_gpu))\n",
    "\n",
    "train_losses = []\n",
    "n_epochs = 300\n",
    "\n",
    "peft_list = []\n",
    "\n",
    "PATH = 'vit_32_384_CUB.pth'\n",
    "\n",
    "from collections import OrderedDict\n",
    "state_dict = torch.load(PATH)\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove module.\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "for batch in batch_list:\n",
    "    support_images, support_labels, query_images, query_labels,_ = batch\n",
    "    support_images = support_images.to(device=device, dtype=torch.float32)\n",
    "    support_labels = support_labels.to(device=device, dtype=torch.long)\n",
    "    query_images = query_images.to(device=device, dtype=torch.float32)\n",
    "    query_labels = query_labels.to(device=device, dtype=torch.long)\n",
    "    \n",
    "    #PEFT\n",
    "    PEFT = 1\n",
    "    num_classes = 5\n",
    "    model_peft = CUBModel(num_classes = num_classes)\n",
    "    print(model_peft.load_state_dict(new_state_dict, strict=False))\n",
    "    if PEFT:\n",
    "        count = 0\n",
    "        for name, param in model_peft.named_parameters():\n",
    "                if 'lk' in name or 'lv' in name or 'fcpeft' in name or 'linear_last' in name:\n",
    "                    param.requires_grad = True\n",
    "                    count += 1\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "        print(count)\n",
    "    print(\"Trainable parameters are (PEFT):\" + str(count_parameters(model_peft)))\n",
    "    for model in [model_peft]:\n",
    "        \n",
    "        model.to(device)\n",
    "        model.train()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n",
    "\n",
    "        total_loss = 0\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        for epochs in range(n_epochs):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(support_images)\n",
    "            \n",
    "            loss = criterion(outputs.squeeze(),support_labels)\n",
    "            \n",
    "            if n_gpu>1:\n",
    "                loss = loss.mean()\n",
    "            \n",
    "            train_loss = loss.item()\n",
    "            total_loss += train_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            if epochs%100 == 0:\n",
    "                print(\"Training Loss is \" + str(total_loss))\n",
    "        print(\"Training Loss is \" + str(total_loss))\n",
    "        results = evaluate_query(model, query_images, query_labels)\n",
    "        print(results.item())\n",
    "        peft_list.append(results.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "203c95b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9139999973773957"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_mean = sum(peft_list)/len(peft_list)\n",
    "peft_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "115e188d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88340597"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "get_n_params(model_peft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "620e2d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 10\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.7479355335235596\n",
      "Training Loss is 52.41307633370161\n",
      "Training Loss is 60.97144044190645\n",
      "Training Loss is 67.06167459487915\n",
      "0.8799999952316284\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 2.009232521057129\n",
      "Training Loss is 58.70551225543022\n",
      "Training Loss is 69.4730398580432\n",
      "Training Loss is 77.13441551476717\n",
      "0.7400000095367432\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.9351396560668945\n",
      "Training Loss is 65.16562560200691\n",
      "Training Loss is 77.23303701728582\n",
      "Training Loss is 85.63835795968771\n",
      "0.9599999785423279\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.6732239723205566\n",
      "Training Loss is 48.85986367613077\n",
      "Training Loss is 57.56248743459582\n",
      "Training Loss is 63.75180060788989\n",
      "0.9599999785423279\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 2.4108784198760986\n",
      "Training Loss is 85.34758470952511\n",
      "Training Loss is 103.01919235289097\n",
      "Training Loss is 115.4323312714696\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.640957236289978\n",
      "Training Loss is 58.94597604870796\n",
      "Training Loss is 70.6647456586361\n",
      "Training Loss is 79.01675564795732\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.839004397392273\n",
      "Training Loss is 58.08541688323021\n",
      "Training Loss is 68.30834740772843\n",
      "Training Loss is 75.43827149644494\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.590377688407898\n",
      "Training Loss is 47.127943858504295\n",
      "Training Loss is 55.642571557313204\n",
      "Training Loss is 61.99179474636912\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.959051251411438\n",
      "Training Loss is 62.446552112698555\n",
      "Training Loss is 73.2741251513362\n",
      "Training Loss is 80.73026019707322\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.455868124961853\n",
      "Training Loss is 55.31123077869415\n",
      "Training Loss is 67.48895158618689\n",
      "Training Loss is 76.15479202568531\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 2.268777370452881\n",
      "Training Loss is 84.01512455940247\n",
      "Training Loss is 103.27552257478237\n",
      "Training Loss is 116.76718639582396\n",
      "0.8799999952316284\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 2.164759874343872\n",
      "Training Loss is 69.01248502731323\n",
      "Training Loss is 82.05973681807518\n",
      "Training Loss is 91.0823087990284\n",
      "0.9599999785423279\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.984626293182373\n",
      "Training Loss is 63.09458161890507\n",
      "Training Loss is 74.9899734929204\n",
      "Training Loss is 83.31776238977909\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.529441237449646\n",
      "Training Loss is 41.42080391198397\n",
      "Training Loss is 48.129150934517384\n",
      "Training Loss is 52.97860758751631\n",
      "0.8799999952316284\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.5262070894241333\n",
      "Training Loss is 49.092985048890114\n",
      "Training Loss is 59.068149887025356\n",
      "Training Loss is 66.40166409686208\n",
      "0.9599999785423279\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.7166334390640259\n",
      "Training Loss is 56.01157312095165\n",
      "Training Loss is 68.23412531614304\n",
      "Training Loss is 77.0103569701314\n",
      "0.9599999785423279\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.4802703857421875\n",
      "Training Loss is 49.00971934199333\n",
      "Training Loss is 58.93705492466688\n",
      "Training Loss is 65.95354874432087\n",
      "0.8399999737739563\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.677357792854309\n",
      "Training Loss is 63.75698447227478\n",
      "Training Loss is 79.40796918421984\n",
      "Training Loss is 90.86472369730473\n",
      "0.8799999952316284\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.6247421503067017\n",
      "Training Loss is 51.70045851171017\n",
      "Training Loss is 62.453462325036526\n",
      "Training Loss is 70.31912384927273\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.7713731527328491\n",
      "Training Loss is 54.071602925658226\n",
      "Training Loss is 64.58376210927963\n",
      "Training Loss is 72.05276035517454\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.7876675128936768\n",
      "Training Loss is 60.401865124702454\n",
      "Training Loss is 72.7036235705018\n",
      "Training Loss is 81.45749502629042\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.942894458770752\n",
      "Training Loss is 63.990290343761444\n",
      "Training Loss is 76.82772777974606\n",
      "Training Loss is 85.84256505966187\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 2.0666444301605225\n",
      "Training Loss is 75.90976285934448\n",
      "Training Loss is 93.77797576785088\n",
      "Training Loss is 106.40894252806902\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.6576446294784546\n",
      "Training Loss is 54.45399349927902\n",
      "Training Loss is 66.50650097429752\n",
      "Training Loss is 75.42540632933378\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 2.1734724044799805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is 69.70986123383045\n",
      "Training Loss is 83.0832047238946\n",
      "Training Loss is 92.63710507750511\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 2.248021125793457\n",
      "Training Loss is 77.57202236354351\n",
      "Training Loss is 94.8772085532546\n",
      "Training Loss is 107.23877052217722\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.909152626991272\n",
      "Training Loss is 64.17970290780067\n",
      "Training Loss is 76.20636510848999\n",
      "Training Loss is 84.75669967383146\n",
      "1.0\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.8528987169265747\n",
      "Training Loss is 67.07585287094116\n",
      "Training Loss is 82.47286323457956\n",
      "Training Loss is 93.39253170788288\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.7410354614257812\n",
      "Training Loss is 54.70988576114178\n",
      "Training Loss is 64.564601957798\n",
      "Training Loss is 71.7532348036766\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.8899632692337036\n",
      "Training Loss is 63.210835710167885\n",
      "Training Loss is 76.28986307233572\n",
      "Training Loss is 85.80299094319344\n",
      "0.9599999785423279\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.8081680536270142\n",
      "Training Loss is 58.03276042640209\n",
      "Training Loss is 68.32403271645308\n",
      "Training Loss is 75.43171609193087\n",
      "0.9599999785423279\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 2.111252546310425\n",
      "Training Loss is 64.59182786941528\n",
      "Training Loss is 76.80419646948576\n",
      "Training Loss is 85.5197791904211\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.6680140495300293\n",
      "Training Loss is 57.22501848638058\n",
      "Training Loss is 68.80655899643898\n",
      "Training Loss is 76.95240466296673\n",
      "0.9599999785423279\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 2.5636532306671143\n",
      "Training Loss is 87.02334861457348\n",
      "Training Loss is 102.029714807868\n",
      "Training Loss is 112.23874653875828\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.757513165473938\n",
      "Training Loss is 64.14485527575016\n",
      "Training Loss is 78.3718144595623\n",
      "Training Loss is 88.4802727252245\n",
      "0.8199999928474426\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.4767358303070068\n",
      "Training Loss is 44.57762922346592\n",
      "Training Loss is 52.63336865231395\n",
      "Training Loss is 58.3640297986567\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.8734289407730103\n",
      "Training Loss is 68.29852963984013\n",
      "Training Loss is 83.36923154443502\n",
      "Training Loss is 94.1498758867383\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.8010458946228027\n",
      "Training Loss is 58.04046541452408\n",
      "Training Loss is 70.04075929522514\n",
      "Training Loss is 78.6842100173235\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 2.1464295387268066\n",
      "Training Loss is 71.14263346791267\n",
      "Training Loss is 84.63117767125368\n",
      "Training Loss is 93.72901938855648\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.9773881435394287\n",
      "Training Loss is 65.41097885370255\n",
      "Training Loss is 79.23892714828253\n",
      "Training Loss is 89.20241966843605\n",
      "0.8399999737739563\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 2.401233434677124\n",
      "Training Loss is 68.77462267875671\n",
      "Training Loss is 77.7977371737361\n",
      "Training Loss is 83.93752371892333\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.618888258934021\n",
      "Training Loss is 59.535196632146835\n",
      "Training Loss is 75.00897645950317\n",
      "Training Loss is 86.24733894318342\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 2.352766513824463\n",
      "Training Loss is 80.22671668231487\n",
      "Training Loss is 95.04163499176502\n",
      "Training Loss is 105.7200758382678\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.967756748199463\n",
      "Training Loss is 61.11878743767738\n",
      "Training Loss is 72.93303792923689\n",
      "Training Loss is 81.53296685963869\n",
      "0.8399999737739563\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.924141526222229\n",
      "Training Loss is 58.944412752985954\n",
      "Training Loss is 69.09264969825745\n",
      "Training Loss is 76.29220439866185\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.6698434352874756\n",
      "Training Loss is 51.59158919006586\n",
      "Training Loss is 61.12868098914623\n",
      "Training Loss is 67.90032621473074\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 2.3598756790161133\n",
      "Training Loss is 74.96465291082859\n",
      "Training Loss is 87.19858831167221\n",
      "Training Loss is 95.95262382179499\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.7973486185073853\n",
      "Training Loss is 70.1853987723589\n",
      "Training Loss is 87.92780722677708\n",
      "Training Loss is 100.65537971258163\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.7999022006988525\n",
      "Training Loss is 61.49172776937485\n",
      "Training Loss is 73.80678263306618\n",
      "Training Loss is 82.36742644011974\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):5005\n",
      "Training Loss is 1.8627973794937134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss is 62.99327786266804\n",
      "Training Loss is 76.55273133516312\n",
      "Training Loss is 86.20826017856598\n",
      "0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "#model.to(device)\n",
    "\n",
    "print(\"Number of GPUs: \"+str(n_gpu))\n",
    "\n",
    "train_losses = []\n",
    "n_epochs = 300\n",
    "\n",
    "peft_list = []\n",
    "\n",
    "PATH = 'vit_32_384_CUB.pth'\n",
    "\n",
    "from collections import OrderedDict\n",
    "state_dict = torch.load(PATH)\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove module.\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "for batch in batch_list:\n",
    "    support_images, support_labels, query_images, query_labels,_ = batch\n",
    "    support_images = support_images.to(device=device, dtype=torch.float32)\n",
    "    support_labels = support_labels.to(device=device, dtype=torch.long)\n",
    "    query_images = query_images.to(device=device, dtype=torch.float32)\n",
    "    query_labels = query_labels.to(device=device, dtype=torch.long)\n",
    "    \n",
    "    #Linear Probe\n",
    "    linear_probe = 1\n",
    "    model_linear = CUBModel(num_classes = num_classes)\n",
    "    print(model_linear.load_state_dict(new_state_dict, strict=False))\n",
    "    if linear_probe:\n",
    "        count = 0\n",
    "        for name, param in model_linear.named_parameters():\n",
    "            if 'linear_last' in name:\n",
    "                    param.requires_grad = True\n",
    "                    count += 1\n",
    "            else:\n",
    "                  param.requires_grad = False\n",
    "        print(count)\n",
    "    print(\"Trainable parameters are (linear Probe):\" + str(count_parameters(model_linear)))\n",
    "    for model in [model_linear]:\n",
    "        \n",
    "        model.to(device)\n",
    "        model.train()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n",
    "\n",
    "        total_loss = 0\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        for epochs in range(n_epochs):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(support_images)\n",
    "            \n",
    "            loss = criterion(outputs.squeeze(),support_labels)\n",
    "            \n",
    "            if n_gpu>1:\n",
    "                loss = loss.mean()\n",
    "            \n",
    "            train_loss = loss.item()\n",
    "            total_loss += train_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            if epochs%100 == 0:\n",
    "                print(\"Training Loss is \" + str(total_loss))\n",
    "        print(\"Training Loss is \" + str(total_loss))\n",
    "        results = evaluate_query(model, query_images, query_labels)\n",
    "        print(results.item())\n",
    "        peft_list.append(results.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2006719d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9235999965667725"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_mean = sum(peft_list)/len(peft_list)\n",
    "peft_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c81ac284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88302197"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "get_n_params(model_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c38d1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 10\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 2.2196006774902344\n",
      "Training Loss is 4.92985132324975\n",
      "Training Loss is 4.960869594098767\n",
      "Training Loss is 4.985465633901185\n",
      "0.9800000190734863\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 1.786980152130127\n",
      "Training Loss is 3.9906130560848396\n",
      "Training Loss is 4.020017030867166\n",
      "Training Loss is 4.043470762349898\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 1.9869985580444336\n",
      "Training Loss is 4.324548768345267\n",
      "Training Loss is 4.353567031779676\n",
      "Training Loss is 4.376600469084224\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 1.614291787147522\n",
      "Training Loss is 3.808834121504333\n",
      "Training Loss is 3.8327702623064397\n",
      "Training Loss is 3.8518907157849753\n",
      "0.8799999952316284\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 1.7946478128433228\n",
      "Training Loss is 4.167019729851745\n",
      "Training Loss is 4.191425422497559\n",
      "Training Loss is 4.2112683274026494\n",
      "0.9599999785423279\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 1.7209736108779907\n",
      "Training Loss is 3.9832350033684634\n",
      "Training Loss is 4.012643025678699\n",
      "Training Loss is 4.036025921581313\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 1.9381380081176758\n",
      "Training Loss is 4.598344488593284\n",
      "Training Loss is 4.629025960457511\n",
      "Training Loss is 4.6537954975356115\n",
      "0.9200000166893005\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 2.0400729179382324\n",
      "Training Loss is 4.640101189172128\n",
      "Training Loss is 4.670781784021528\n",
      "Training Loss is 4.695349956222344\n",
      "1.0\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 1.8779772520065308\n",
      "Training Loss is 4.184535749605857\n",
      "Training Loss is 4.210937566400389\n",
      "Training Loss is 4.231988447078038\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 1.8305580615997314\n",
      "Training Loss is 4.177777585893637\n",
      "Training Loss is 4.203711029898841\n",
      "Training Loss is 4.224371522097499\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 2.0574188232421875\n",
      "Training Loss is 5.069913417653879\n",
      "Training Loss is 5.101337489497382\n",
      "Training Loss is 5.126639409078052\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 2.2604775428771973\n",
      "Training Loss is 5.264878211193718\n",
      "Training Loss is 5.297178403736325\n",
      "Training Loss is 5.323430635748082\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 1.8003485202789307\n",
      "Training Loss is 3.8498745303077158\n",
      "Training Loss is 3.877066411456326\n",
      "Training Loss is 3.8990819308673963\n",
      "1.0\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 1.6635593175888062\n",
      "Training Loss is 3.276594464376103\n",
      "Training Loss is 3.2988099009235157\n",
      "Training Loss is 3.31700358116359\n",
      "0.8999999761581421\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 1.9745827913284302\n",
      "Training Loss is 4.521485952223884\n",
      "Training Loss is 4.550129603390815\n",
      "Training Loss is 4.573355005602934\n",
      "0.9399999976158142\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (linear Probe):88302197\n",
      "Training Loss is 1.7489384412765503\n",
      "Training Loss is 4.029854265507311\n",
      "Training Loss is 4.056689747070777\n",
      "Training Loss is 4.078346971946303\n",
      "0.9399999976158142\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "#model.to(device)\n",
    "\n",
    "print(\"Number of GPUs: \"+str(n_gpu))\n",
    "\n",
    "train_losses = []\n",
    "n_epochs = 300\n",
    "\n",
    "peft_list = []\n",
    "\n",
    "PATH = 'vit_32_384_CUB.pth'\n",
    "\n",
    "from collections import OrderedDict\n",
    "state_dict = torch.load(PATH)\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove module.\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "for batch in batch_list:\n",
    "    support_images, support_labels, query_images, query_labels,_ = batch\n",
    "    support_images = support_images.to(device=device, dtype=torch.float32)\n",
    "    support_labels = support_labels.to(device=device, dtype=torch.long)\n",
    "    query_images = query_images.to(device=device, dtype=torch.float32)\n",
    "    query_labels = query_labels.to(device=device, dtype=torch.long)\n",
    "    \n",
    "    model_full = CUBModel(num_classes = num_classes)\n",
    "    print(model_full.load_state_dict(new_state_dict, strict=False))\n",
    "    print(\"Trainable parameters are (linear Probe):\" + str(count_parameters(model_full)))\n",
    "    for model in [model_full]:\n",
    "        \n",
    "        model.to(device)\n",
    "        model.train()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n",
    "\n",
    "        total_loss = 0\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        for epochs in range(n_epochs):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(support_images)\n",
    "            \n",
    "            loss = criterion(outputs.squeeze(),support_labels)\n",
    "            \n",
    "            if n_gpu>1:\n",
    "                loss = loss.mean()\n",
    "            \n",
    "            train_loss = loss.item()\n",
    "            total_loss += train_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            if epochs%100 == 0:\n",
    "                print(\"Training Loss is \" + str(total_loss))\n",
    "        print(\"Training Loss is \" + str(total_loss))\n",
    "        results = evaluate_query(model, query_images, query_labels)\n",
    "        print(results.item())\n",
    "        peft_list.append(results.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae884e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_mean = sum(peft_list)/len(peft_list)\n",
    "peft_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf70bb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88302197"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "get_n_params(model_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bcf20ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 10\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "2\n",
      "Trainable parameters are (linear Probe):140140\n",
      "_IncompatibleKeys(missing_keys=['linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "Trainable parameters are (full model):88437332\n",
      "_IncompatibleKeys(missing_keys=['vit.transformer.blocks.0.attn.lk.weights', 'vit.transformer.blocks.0.attn.lv.weights', 'vit.transformer.blocks.0.pwff.fcpeft.weights', 'vit.transformer.blocks.1.attn.lk.weights', 'vit.transformer.blocks.1.attn.lv.weights', 'vit.transformer.blocks.1.pwff.fcpeft.weights', 'vit.transformer.blocks.2.attn.lk.weights', 'vit.transformer.blocks.2.attn.lv.weights', 'vit.transformer.blocks.2.pwff.fcpeft.weights', 'vit.transformer.blocks.3.attn.lk.weights', 'vit.transformer.blocks.3.attn.lv.weights', 'vit.transformer.blocks.3.pwff.fcpeft.weights', 'vit.transformer.blocks.4.attn.lk.weights', 'vit.transformer.blocks.4.attn.lv.weights', 'vit.transformer.blocks.4.pwff.fcpeft.weights', 'vit.transformer.blocks.5.attn.lk.weights', 'vit.transformer.blocks.5.attn.lv.weights', 'vit.transformer.blocks.5.pwff.fcpeft.weights', 'vit.transformer.blocks.6.attn.lk.weights', 'vit.transformer.blocks.6.attn.lv.weights', 'vit.transformer.blocks.6.pwff.fcpeft.weights', 'vit.transformer.blocks.7.attn.lk.weights', 'vit.transformer.blocks.7.attn.lv.weights', 'vit.transformer.blocks.7.pwff.fcpeft.weights', 'vit.transformer.blocks.8.attn.lk.weights', 'vit.transformer.blocks.8.attn.lv.weights', 'vit.transformer.blocks.8.pwff.fcpeft.weights', 'vit.transformer.blocks.9.attn.lk.weights', 'vit.transformer.blocks.9.attn.lv.weights', 'vit.transformer.blocks.9.pwff.fcpeft.weights', 'vit.transformer.blocks.10.attn.lk.weights', 'vit.transformer.blocks.10.attn.lv.weights', 'vit.transformer.blocks.10.pwff.fcpeft.weights', 'vit.transformer.blocks.11.attn.lk.weights', 'vit.transformer.blocks.11.attn.lv.weights', 'vit.transformer.blocks.11.pwff.fcpeft.weights', 'linear_last.weight', 'linear_last.bias'], unexpected_keys=['linear1.weight', 'linear1.bias'])\n",
      "38\n",
      "Trainable parameters are (PEFT):43405\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MultiHeadedSelfAttention' object has no attribute 'lk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 83\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epochs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m     82\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 83\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupport_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(),support_labels)\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_gpu\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn [10], line 8\u001b[0m, in \u001b[0;36mCUBModel.forward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, xb):\n\u001b[0;32m----> 8\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m     10\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_last(out)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn [8], line 164\u001b[0m, in \u001b[0;36mViT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositional_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m): \n\u001b[1;32m    163\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_embedding(x)  \u001b[38;5;66;03m# b,gh*gw+1,d \u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# b,gh*gw+1,d\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_logits\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    166\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_logits(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn [7], line 139\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 139\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn [7], line 123\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask):\n\u001b[0;32m--> 123\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    124\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m h\n\u001b[1;32m    125\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpwff(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x)))\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn [7], line 69\u001b[0m, in \u001b[0;36mMultiHeadedSelfAttention.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#PEFT\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PEFT:\n\u001b[0;32m---> 69\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlk\u001b[49m(k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     70\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlv(v)\n\u001b[1;32m     71\u001b[0m     scores \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m@\u001b[39m k \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(k\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:947\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m    946\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m--> 947\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiHeadedSelfAttention' object has no attribute 'lk'"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "#model.to(device)\n",
    "\n",
    "print(\"Number of GPUs: \"+str(n_gpu))\n",
    "\n",
    "train_losses = []\n",
    "n_epochs = 300\n",
    "\n",
    "acc_list = []\n",
    "\n",
    "PATH = 'vit_32_384_CUB.pth'\n",
    "\n",
    "from collections import OrderedDict\n",
    "state_dict = torch.load(PATH)\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove module.\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "\n",
    "\n",
    "for batch in test_loader:\n",
    "    support_images, support_labels, query_images, query_labels,_ = batch\n",
    "    support_images = support_images.to(device=device, dtype=torch.float32)\n",
    "    support_labels = support_labels.to(device=device, dtype=torch.long)\n",
    "    query_images = query_images.to(device=device, dtype=torch.float32)\n",
    "    query_labels = query_labels.to(device=device, dtype=torch.long)\n",
    "\n",
    "    #Linear Probe\n",
    "    linear_probe = 1\n",
    "    model_linear = CUBModel(num_classes = num_classes)\n",
    "    print(model_linear.load_state_dict(new_state_dict, strict=False))\n",
    "    if linear_probe:\n",
    "        count = 0\n",
    "        for name, param in model_linear.named_parameters():\n",
    "            if 'linear_last' in name:\n",
    "                    param.requires_grad = True\n",
    "                    count += 1\n",
    "            else:\n",
    "                  param.requires_grad = False\n",
    "        print(count)\n",
    "    print(\"Trainable parameters are (linear Probe):\" + str(count_parameters(model_linear)))\n",
    "    #Full model fine tuning\n",
    "    model_full = CUBModel(num_classes = num_classes)\n",
    "    \n",
    "    print(model_full.load_state_dict(new_state_dict, strict=False))\n",
    "    print(\"Trainable parameters are (full model):\" + str(count_parameters(model_full)))\n",
    "    \n",
    "    #PEFT\n",
    "    PEFT = 1\n",
    "    num_classes = 5\n",
    "    model_peft = CUBModel(num_classes = num_classes)\n",
    "    print(model_peft.load_state_dict(new_state_dict, strict=False))\n",
    "    if PEFT:\n",
    "        count = 0\n",
    "        for name, param in model_peft.named_parameters():\n",
    "                if 'lk' in name or 'lv' in name or 'fcpeft' in name or 'linear_last' in name:\n",
    "                    param.requires_grad = True\n",
    "                    count += 1\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "        print(count)\n",
    "    print(\"Trainable parameters are (PEFT):\" + str(count_parameters(model_peft)))\n",
    "    for model in [model_linear, model_full, model_peft]:\n",
    "        \n",
    "        model.to(device)\n",
    "        model.train()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n",
    "\n",
    "        total_loss = 0\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        for epochs in range(n_epochs):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(support_images)\n",
    "            \n",
    "            loss = criterion(outputs.squeeze(),support_labels)\n",
    "            \n",
    "            if n_gpu>1:\n",
    "                loss = loss.mean()\n",
    "            \n",
    "            train_loss = loss.item()\n",
    "            total_loss += train_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            if epochs%100 == 0:\n",
    "                print(\"Training Loss is \" + str(total_loss))\n",
    "        print(\"Training Loss is \" + str(total_loss))\n",
    "        results = evaluate_query(model, query_images, query_labels)\n",
    "        print(results.item())\n",
    "        acc_list.append(results.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c1166d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9296153783798218 0.9298039183897131 0.9294117583948023\n"
     ]
    }
   ],
   "source": [
    "lin_list = []\n",
    "full_list = []\n",
    "peft_list = []\n",
    "for i in range(len(acc_list)):\n",
    "    if i % 3 == 0:\n",
    "        lin_list.append(acc_list[i])\n",
    "    elif i % 3 == 1:\n",
    "        full_list.append(acc_list[i])\n",
    "    elif i % 3 == 2:\n",
    "        peft_list.append(acc_list[i])\n",
    "\n",
    "lin_mean = sum(lin_list)/len(lin_list)\n",
    "full_mean = sum(full_list)/len(full_list)\n",
    "peft_mean = sum(peft_list)/len(peft_list)\n",
    "print(lin_mean, full_mean, peft_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c8486c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2275a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_list = []\n",
    "full_list = []\n",
    "peft_list = []\n",
    "for i in range(len(acc_list)):\n",
    "    if i % 3 == 0:\n",
    "        lin_list.append(acc_list[i])\n",
    "    elif i % 3 == 1:\n",
    "        full_list.append(acc_list[i])\n",
    "    elif i % 3 == 2:\n",
    "        peft_list.append(acc_list[i])\n",
    "\n",
    "lin_mean = sum(lin_list)/len(lin_list)\n",
    "full_mean = sum(full_list)/len(full_list)\n",
    "peft_mean = sum(peft_list)/len(peft_list)\n",
    "print(lin_mean, full_mean, peft_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0842a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2e6a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a08fe042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204257909"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_params(model_peft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fe4849b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88302197"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "762cde8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115960717"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model_peft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3731cfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
